# ABHIJIT GOKHALE
*agokhale@syr.edu | abhijit5october@gmail.com | +1-(315) 278-4351 | [LinkedIn](https://www.linkedin.com/in/abhijitgokhale/) | [GitHub](https://github.com/AbhijitGokhale) | [HackerRank](https://www.hackerrank.com/agokhale4) | [PLUM Behavioral Profile](https://secure.plum.io/en/p/H9mMpam2DX7DlEJ9LST0mw)*

*Data Scientist Intern, Caterpillar | Data Analyst, Accenture | Data Science Teaching Assistant, Syracuse University*

# PROFILE SUMMARY
5 years of diverse work experience in data field on client facing & product development roles in data engineering, data science, data analytics, business intelligence. Demonstrated analytical problem solving, leadership, and effective communication to work with internal, and external partners.


# EDUCATION
* Masters of Science (Data Science), *Syracuse University*, 2021-2022
* Bachelors of Science (Data Science), *Mumbai University*, 2012-2016


# LEADERSHIP
***Data Science Teaching Assistant, Syracuse University (Sept 2021 – Dec 2022)***
Delivered assistance to program director and professors, in interpreting statistical and machine learning results in R programming with 9 classes of 30 students each for 22 labs, and 3 projects for Introduction to Data Science course. 


# WORK EXPERIENCE
***Data Scientist Intern, Caterpillar, Chicago, Illinois (May 2022 – Aug 2022)***	
* Analyzed 341 machine’s engine removal data using python pandas to predict survival or risk probability of engine shutdown.
* Performed feature selection using nonparametric log rank test with Kaplan-Meier, correlation analysis, & feature importance.
* Delivered machine learning prototype, with Git version control, consist of stratification data sampling, hyperparameter tuning using grid-search 5-fold cross validation for Survival Analysis supervised learning algorithms such as Extra Survival Trees, Random Survival Forest, Gradient Boosting, Cox-PH to get best evaluation Concordance Index ( > 0.5 ) and Brier Score. 
* Recommended probability of survival / risk with significant features (P-value < 0.05) by simulating 12% of test data samples.

***Data Analyst, Accenture, Mumbai, India (Dec 2016 – Aug 2020)***	
* Developed & enhanced Informatica ETL jobs on 4+ mil. data to perform big data analysis – data partitioning, clustered index, reusable database objects with DDL, DML, DCL, & TCL SQL operations using Agile methodology & CI/CD approach.
* Designed SDLC including logical data modeling for 20+ databases & 100 + tables to maintain data quality, and data privacy.
* Led a 6 - analysts team to deploy ETL jobs from QA to PROD linked with 100+ Jira items with SAT & UAT executions.
* Improved the SSIS project flow by 30% and resolved 60% of major daily batch job issues using MS SQL server and HiveQL.
* Automated exploratory data analysis using Python for 15 raw files & delivered key performance indicators to maximize profit, revenue by 20 dashboards & reports using MS Power BI & Excel  - solver optimization & DAX functionality.


# PROJECTS
Below projects highlight technical skills in Data Engineering, Data Analytics, and Machine Learning using Python, PySpark, R, SQL, NoSQL, Tableau, and MS Power BI.


## [Credit Card Fraud Detection](https://github.com/AbhijitGokhale/Credit-Card-Fraud-Detetction)
Utilize existing credit card fraud data from January 2019 to December 2020 and develop a machine learning model in PySpark to perform Big Data Analysis which inturn leads to the best prediction results in revealing and preventing fraudulent transactions.

* Built Random Forest, Gradient Boosting with 3-fold cross validation, hyperparameter tunning for 1.8 mil imbalanced data.
* Predicted fraudulent credit card customer transactions by maximizing the F1 score with 90% precision, classification accuracy.

  * **PySpark Libraries used:** pandas, numpy, seaborn, plotly, pyspark.sql, spark.ml
  * **Python libraries used:** pandas, numpy, scipy, sklearn, seaborn, plotly
  * **Input:** 1.8 Million rows consisting Financial and Demographic Information
  * **Output:** Fraudulent and Legitimate Credit Card Transaction Classification with a probability giving optimized F-1 Score


## [Statistical & Predictive Analysis - Vaccination Rates in Californian School Districts](https://github.com/AbhijitGokhale/Statistical-Analysis-on-California-School-Districts-Vaccination)
The project explains specific and appropriate statistical values; both frequentist and Bayesian inferential evidence; explanation including both data exploration and cleaning and appropriate diagnostics.

* Analyzed 15 years incremental trend, seasonality, variations in socioeconomic features through hypothesis driven EDA.
* Determined statistically significant features using hypothesis test, t-test, ANOVA, MCMC Confidence Interval.
* Delivered actionable insights based on linear & logistic regressions with 80% accuracy to improve total vaccination rate 

  * **R Libraries:** tidyverse, ggplot2, dplyr, psych, dlookr, tseries, car, DHARMa, lm.beta, BayesFactor, performance, caret, MCMCpack
  * **Input:** RData file contains two data sets that pertain to vaccinations for the U.S. as a whole and for Californian school districts. The U.S. vaccine data is a time series, and the California data is a sample of end-of-year vaccination reports from n=700 school districts.
  * **Output:** Necessary statistical analysis of vaccination rates in California school districts.


## [USA B2B & B2C Customer Sales Analysis Report 2020 to 2021](https://public.tableau.com/app/profile/abhijit.gokhale/viz/CustomerSalesAnalysisReport2020-2021/CustomerSalesAnalysisReport2020-2021)
Interactive Tableau dashboards with BI reports by leveraging the feasibility to use Built-in and customized visualizations, parameters and fields for a customer transaction data - Total 36 columns with 280000 records.

* Designed & published 3 interactive Tableau dashboards & BI reports for 280K data using built-in & custom objects.
* Accomplished deliverables to visualize the impact of yearly trends in product categories, order status, payment methods.

  * **Software:** Tableau Desktop
  * **Input:** Excel files
  * **Output:** (https://public.tableau.com/app/profile/abhijit.gokhale/viz/CustomerSalesAnalysisReport2020-2021/CustomerSalesAnalysisReport2020-2021)


## [Covid-19 Patient's Pre-Condition Analysis](https://github.com/AbhijitGokhale/Covid-19-Patient-s-Pre-Condition-Analysis)
Analyze the factors that influence mortality in patients who do not need an intensive care unit and those who do. What are the underlying comorbidities that patients are likely to test positive for COVID? Which factors influence the need for an intensive care unit? This can help with patient triage, optimal distribution of vaccinations (if needed) in countries with limited resources, or prevention in countries susceptible to the virus.

* Analyzed 1 year trend on 560K data and interpreted 3-fold cross validated Random Forest and Gradient Boosting models.
* Showcased actionable insights to treat all age patients by classifying features - ICU requirement, Covid-19 result, and death based on date of symptoms, hospitalization, and patient’s death to reduce the mortality by 70% and save hospitalization costs.

  * **Python Libraries:** pandas, numpy, scipy, sklearn, seaborn, plotly, matplotlib
  * **Input:** Patient's medical pre conditions binomial data
  * **Output:** Classification of requirement of ICU, and classification of chance of getting Covid based on Mortality


## [Tweeter Text Analysis using AWS Neptune](https://github.com/AbhijitGokhale/Tweeter-Text-Analysis-using-AWS-Neptune)
A high performance, scalable, secure, and cost effective NoSQL AWS Neptune database to perform fast information retrieval among edges and nodes.

* Built AWS Neptune graph database by executing Cypher and Gremlin queries in AWS Sagemaker Jupyter Notebook based on 17 nodes and 4 different edges to traverse quickly & recommend the tweets, retweets, and hashtags.
* Facilitated the S3 bucket instance to bulk load data files, and IAM role assignment to provide read-write access. 

  * **Infrastructure:** AWS Cloud
  * **AWS Cloud Services:** S3, IAM, Neptune, VPC, Sagemaker
  * **Input:** Bulk load csv files
  * **Programming Language:** Cypher Query Language, Gremlin
  * **Output:** Graph with 17 nodes and 3 different edges
  * **Project Demo URL:** https://video.syr.edu/media/t/1_n773smyp


## [Soccer Database Management](https://github.com/AbhijitGokhale/Soccer-Database-Management)
Soccer database management projects presents unique MS SQL server backend with frontend developed in Microsoft PowerApps.
* **Data Model:** draw.io for E-R Diagrams and Logical Data Modeling\
* **Relational Databases (Backend Interface):** MS SQL Server with DDL, DML, DCL, and TCL operations
* **Frontend Application UI:** Microsoft PowerApps
* **Backend Application Interface:** MS SQL Server
* **Project Demo URL:** https://video.syr.edu/media/t/1_niyvyvxd


## [Amazon Price Tracker - Web Scraping](https://github.com/AbhijitGokhale/Amazon-Price-Tracker)
Recently there was an Amazon sale and I wanted to buy a product that I had been checking on for a long time. But, as I was ready to buy it I noticed that the price had increased and I wondered if the sale was even legitimate. So I figured by creating this price tracker app, it would not only increase my fluency in python but I would also have my very own home-brewed app to track amazon prices.
* **Python Libraries:** requests,BeautifulSoup, time, smtplib
* **Input:** Product URL, Sender and Receiver Email Adresses (one / many), Price Threshold value 
* **Output:** smtplib to trigger an email with changed price amount
